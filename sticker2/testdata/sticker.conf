[input]
vocab = "bert-base-german-cased-vocab.txt"

[labeler]
labels = "sticker.labels"
encoders = [
  { name = "dep", encoder = { dependency = "relativepos" } },
  { name = "lemma", encoder = { lemma = "form" } },
  { name = "pos", encoder = { sequence = "pos" } },
]

[model]
parameters = "epoch-99"
position_embeddings = "model"
pretrain_config = "bert_config.json"
pretrain_type = "bert"